{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Assembly DSI - Denver 2018\n",
    "## Capstone Project - DFS Model\n",
    "This is my capstone project at General Assembly's fifth [Data Science Immersive](https://generalassemb.ly/education/data-science-immersive) cohort in 2018. I am developing a model to assist in optimizing NFL lineups on the daily fantasy sports platforms [Draft Kings](https://www.draftkings.com/) and [Fan Duel](https://www.fanduel.com/).\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Can we build a model to predict a football player’s fantasy football performance to estimate their value and implement the model in conjunction with a daily fantasy strategy to be profitable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charleydixon/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/Users/charleydixon/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('../data/modeling_wrs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.groupby(['Name', 'Year', 'Week', 'Month', 'Team', 'Oppt']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>h/a</th>\n",
       "      <th>Favored</th>\n",
       "      <th>Spread</th>\n",
       "      <th>O/U</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Receptions</th>\n",
       "      <th>Targets</th>\n",
       "      <th>Rec_TDs</th>\n",
       "      <th>...</th>\n",
       "      <th>Weather_DOME</th>\n",
       "      <th>Weather_Fog</th>\n",
       "      <th>Weather_Rain</th>\n",
       "      <th>Weather_Rain | Fog</th>\n",
       "      <th>Weather_Snow</th>\n",
       "      <th>Weather_Snow | Fog</th>\n",
       "      <th>Weather_Snow | Freezing Rain</th>\n",
       "      <th>Weather_Sunny</th>\n",
       "      <th>FD salary</th>\n",
       "      <th>FD points</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Week</th>\n",
       "      <th>Month</th>\n",
       "      <th>Team</th>\n",
       "      <th>Oppt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Adams, Davante</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2014</th>\n",
       "      <th>2</th>\n",
       "      <th>September</th>\n",
       "      <th>GB</th>\n",
       "      <th>NYJ</th>\n",
       "      <td>21.264</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>46.5</td>\n",
       "      <td>63.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4700.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>September</th>\n",
       "      <th>GB</th>\n",
       "      <th>DET</th>\n",
       "      <td>21.271</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>52.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>September</th>\n",
       "      <th>GB</th>\n",
       "      <th>CHI</th>\n",
       "      <td>21.278</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>October</th>\n",
       "      <th>GB</th>\n",
       "      <th>MIN</th>\n",
       "      <td>21.282</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>46.5</td>\n",
       "      <td>63.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>October</th>\n",
       "      <th>GB</th>\n",
       "      <th>MIA</th>\n",
       "      <td>21.292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Age  h/a  Favored  Spread  \\\n",
       "Name           Year Week Month     Team Oppt                                 \n",
       "Adams, Davante 2014 2    September GB   NYJ   21.264    1        1    -7.0   \n",
       "                    3    September GB   DET   21.271    0        0    -1.5   \n",
       "                    4    September GB   CHI   21.278    0        1    -2.0   \n",
       "                    5    October   GB   MIN   21.282    1        1    -8.5   \n",
       "                    6    October   GB   MIA   21.292    0        1    -1.5   \n",
       "\n",
       "                                               O/U  Temperature  Wind  \\\n",
       "Name           Year Week Month     Team Oppt                            \n",
       "Adams, Davante 2014 2    September GB   NYJ   46.5         63.0  11.0   \n",
       "                    3    September GB   DET   52.0         72.0   0.0   \n",
       "                    4    September GB   CHI   51.0         78.0   6.0   \n",
       "                    5    October   GB   MIN   46.5         63.0   7.0   \n",
       "                    6    October   GB   MIA   47.0         88.0  12.0   \n",
       "\n",
       "                                              Receptions   Targets   Rec_TDs  \\\n",
       "Name           Year Week Month     Team Oppt                                   \n",
       "Adams, Davante 2014 2    September GB   NYJ     3.000000  6.333333  0.000000   \n",
       "                    3    September GB   DET     2.666667  5.000000  0.000000   \n",
       "                    4    September GB   CHI     3.000000  4.666667  0.000000   \n",
       "                    5    October   GB   MIN     3.000000  4.333333  0.000000   \n",
       "                    6    October   GB   MIA     1.666667  3.333333  0.333333   \n",
       "\n",
       "                                                ...      Weather_DOME  \\\n",
       "Name           Year Week Month     Team Oppt    ...                     \n",
       "Adams, Davante 2014 2    September GB   NYJ     ...                 0   \n",
       "                    3    September GB   DET     ...                 1   \n",
       "                    4    September GB   CHI     ...                 0   \n",
       "                    5    October   GB   MIN     ...                 0   \n",
       "                    6    October   GB   MIA     ...                 0   \n",
       "\n",
       "                                              Weather_Fog  Weather_Rain  \\\n",
       "Name           Year Week Month     Team Oppt                              \n",
       "Adams, Davante 2014 2    September GB   NYJ             0             0   \n",
       "                    3    September GB   DET             0             0   \n",
       "                    4    September GB   CHI             0             0   \n",
       "                    5    October   GB   MIN             1             0   \n",
       "                    6    October   GB   MIA             0             0   \n",
       "\n",
       "                                              Weather_Rain | Fog  \\\n",
       "Name           Year Week Month     Team Oppt                       \n",
       "Adams, Davante 2014 2    September GB   NYJ                    0   \n",
       "                    3    September GB   DET                    0   \n",
       "                    4    September GB   CHI                    0   \n",
       "                    5    October   GB   MIN                    0   \n",
       "                    6    October   GB   MIA                    0   \n",
       "\n",
       "                                              Weather_Snow  \\\n",
       "Name           Year Week Month     Team Oppt                 \n",
       "Adams, Davante 2014 2    September GB   NYJ              0   \n",
       "                    3    September GB   DET              0   \n",
       "                    4    September GB   CHI              0   \n",
       "                    5    October   GB   MIN              0   \n",
       "                    6    October   GB   MIA              0   \n",
       "\n",
       "                                              Weather_Snow | Fog  \\\n",
       "Name           Year Week Month     Team Oppt                       \n",
       "Adams, Davante 2014 2    September GB   NYJ                    0   \n",
       "                    3    September GB   DET                    0   \n",
       "                    4    September GB   CHI                    0   \n",
       "                    5    October   GB   MIN                    0   \n",
       "                    6    October   GB   MIA                    0   \n",
       "\n",
       "                                              Weather_Snow | Freezing Rain  \\\n",
       "Name           Year Week Month     Team Oppt                                 \n",
       "Adams, Davante 2014 2    September GB   NYJ                              0   \n",
       "                    3    September GB   DET                              0   \n",
       "                    4    September GB   CHI                              0   \n",
       "                    5    October   GB   MIN                              0   \n",
       "                    6    October   GB   MIA                              0   \n",
       "\n",
       "                                              Weather_Sunny  FD salary  \\\n",
       "Name           Year Week Month     Team Oppt                             \n",
       "Adams, Davante 2014 2    September GB   NYJ               1     4700.0   \n",
       "                    3    September GB   DET               0     4600.0   \n",
       "                    4    September GB   CHI               1     4500.0   \n",
       "                    5    October   GB   MIN               0     4500.0   \n",
       "                    6    October   GB   MIA               1     4900.0   \n",
       "\n",
       "                                              FD points  \n",
       "Name           Year Week Month     Team Oppt             \n",
       "Adams, Davante 2014 2    September GB   NYJ         7.5  \n",
       "                    3    September GB   DET         2.1  \n",
       "                    4    September GB   CHI         2.8  \n",
       "                    5    October   GB   MIN         7.6  \n",
       "                    6    October   GB   MIA        10.7  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "- Linear Regression\n",
    "- Random Forest\n",
    "- Support Vector Regression\n",
    "- Boosting\n",
    "- PCA\n",
    "- Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============EVAULATION=============\n",
      "\n",
      "R2 Training: 0.21357368801925125\n",
      "R2 Testing: 0.19696907087177018\n",
      "RMSE: 6.188420455379233\n",
      "MAE: 4.8720054200683105 \n",
      "\n",
      "=============COEFFICIENTS=============\n",
      "\n",
      "Intercept: -4.885523943097192\n",
      "Age -0.006861437450359716\n",
      "h/a 0.2552276368073809\n",
      "Favored 0.5722819328597738\n",
      "Spread -0.04549945815720833\n",
      "O/U 0.04432805984737186\n",
      "Temperature 0.0035347967703881493\n",
      "Wind -0.03859521810994177\n",
      "Receptions 0.08663763483670646\n",
      "Targets 0.47315325262832025\n",
      "Rec_TDs -0.310114707651849\n",
      "Rec_Yds 0.01705604420446762\n",
      "Opp_Rank -0.03765596806172487\n",
      "Opp_Avg_Rec_Allowed -0.18453892568859978\n",
      "Opp_Avg_Targets_Allowed 0.12541076175593396\n",
      "Opp_Avg_TDs_Allowed 0.1155990766202968\n",
      "Opp_Avg_Yds_Allowed 0.004851222386516624\n",
      "Weather_DOME -0.3011350866689547\n",
      "Weather_Fog 1.1584893507770873\n",
      "Weather_Rain -1.3974150526353875\n",
      "Weather_Rain | Fog -1.9376802347148876\n",
      "Weather_Snow -0.09826526179660736\n",
      "Weather_Snow | Fog -1.4079746315088875\n",
      "Weather_Snow | Freezing Rain 4.1168075185894475\n",
      "Weather_Sunny -0.13282660204181437\n",
      "FD salary 0.0011394086316156163\n"
     ]
    }
   ],
   "source": [
    "columns = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "def linreg(df, features, target = 'FD points'):\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "    # first attempt - all features\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print('=============EVAULATION=============\\n')\n",
    "    print('R2 Training:', model.score(X_train, y_train))\n",
    "    print('R2 Testing:', model.score(X_test, y_test))\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    print('RMSE:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "    print('MAE:', mean_absolute_error(y_test, predictions), '\\n')\n",
    "    print('=============COEFFICIENTS=============\\n')\n",
    "    print('Intercept:', model.intercept_)\n",
    "    for key, index in dict(zip(X.columns, model.coef_)).items():\n",
    "        print(key, index)\n",
    "    return model\n",
    "\n",
    "lr_all_features = linreg(data, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Coefficients that seem logical:\n",
    "- Increasing Prediction for:\n",
    "    - Home/Away\n",
    "    - Favored\n",
    "    - O/U\n",
    "    - Attempts\n",
    "    - Completions\n",
    "    - TDs\n",
    "    - Y/A\n",
    "    \n",
    "- Decreasing Prediction for:\n",
    "    - Age\n",
    "        - Sort of...\n",
    "    - Wind\n",
    "    - Rain\n",
    "    - Rain & Fog\n",
    "    - Snow\n",
    "    - Snow & Fog\n",
    "    - Interceptions\n",
    "    - Opponent Rank\n",
    "        - The rank columns is actually backwards so defenses get better as ranking improves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Coefficients that make no sense to me:\n",
    "- Increasing Prediction for:\n",
    "    - Fog\n",
    "    - Snow & Freezing Rain\n",
    "    - Opponent Interceptions\n",
    "- Decreasing Prediction for:\n",
    "    - Being in a Dome (Controlled conditions seem like a player should perform better)\n",
    "    - Sunny weather\n",
    "    - Yards\n",
    "    - Opponent Attempts Allowed\n",
    "    - Opponent Completions Allowed\n",
    "    - Opponent TDs Allowed\n",
    "- Almost no effect from:\n",
    "    - Rating\n",
    "    - FD Salary\n",
    "        - Considering salary kind of derives FanDuel's predictions I feel like this would have an impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The most interesting thing to note here is that FD Salary has seemingly no effect on a player's point production**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_cols = ['Weather_Fog', 'Weather_Snow | Freezing Rain', 'Opp_Avg_Ints', 'Weather_DOME', \n",
    "#                'Weather_Sunny', 'Yards', 'Opp_Avg_Att_Allowed', 'Opp_Avg_Comp_Allowed', \n",
    "#                'Opp_Avg_TDs_Allowed', 'Rating', 'FD salary', 'FD points']\n",
    "\n",
    "# features = [col for col in data.columns if col not in remove_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_partial_features = linreg(data, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0871482416750317"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "cross_val_score(model, X_train, y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07771621227128389"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.171330900243308"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.6320220870789965"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [10, 20, 30], 'n_estimators': [70, 75, 80], 'min_samples_leaf': [13, 14], 'max_features': [10, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "\n",
    "params = {\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'n_estimators': [70, 75, 80],\n",
    "    'min_samples_leaf': [13, 14],\n",
    "    'max_features': [10, 20]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, param_grid = params)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2068915814783504\n",
      "0.2126738536661117\n",
      "{'max_depth': 10, 'max_features': 10, 'min_samples_leaf': 14, 'n_estimators': 70}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.score(X_test, y_test))\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.803901213315784\n",
      "6.1276085537387015\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': 0.042852465031718405,\n",
       " 'h/a': 0.0076890290534770206,\n",
       " 'Favored': 0.006583117747507625,\n",
       " 'Spread': 0.03186644865114176,\n",
       " 'O/U': 0.030871149882189933,\n",
       " 'Temperature': 0.026399446904268903,\n",
       " 'Wind': 0.021896126138596022,\n",
       " 'Receptions': 0.1357554470271299,\n",
       " 'Targets': 0.13454196307860303,\n",
       " 'Rec_TDs': 0.014690897468737809,\n",
       " 'Rec_Yds': 0.09176327420856034,\n",
       " 'Opp_Rank': 0.03405512775163478,\n",
       " 'Opp_Avg_Rec_Allowed': 0.02722977481038195,\n",
       " 'Opp_Avg_Targets_Allowed': 0.029434658805580622,\n",
       " 'Opp_Avg_TDs_Allowed': 0.01274177110292533,\n",
       " 'Opp_Avg_Yds_Allowed': 0.03440317533452358,\n",
       " 'Weather_DOME': 0.0017255591316203442,\n",
       " 'Weather_Fog': 0.0,\n",
       " 'Weather_Rain': 0.000394286287090537,\n",
       " 'Weather_Rain | Fog': 0.0,\n",
       " 'Weather_Snow': 0.0,\n",
       " 'Weather_Snow | Fog': 0.0,\n",
       " 'Weather_Snow | Freezing Rain': 0.0,\n",
       " 'Weather_Sunny': 0.0023892838557111077,\n",
       " 'FD salary': 0.3127169977286008}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(X.columns, gs.best_estimator_.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now this is telling me that `FD Salary` is far and away the most important feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12586005050609317"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0569092544139942"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.335342506968317"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'kernel': ['linear'], 'C': [0.1, 0.01]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVR()\n",
    "params = {\n",
    "    'kernel': ['linear'],\n",
    "    'C': [0.1, 0.01]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, param_grid = params)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18089369199635677\n",
      "0.19445179950476554\n",
      "{'C': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.score(X_test, y_test))\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.747239064240706\n",
      "6.198112326554158\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADA Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
       "         n_estimators=50, random_state=None),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [45, 47, 50], 'learning_rate': [0.8, 0.83, 0.85, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdaBoostRegressor()\n",
    "params = {\n",
    "    'n_estimators': [45, 47, 50],\n",
    "    'learning_rate': [.8, .83, .85, .9]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, param_grid=params)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12143584301619473\n",
      "-0.09575397292913768\n",
      "{'learning_rate': 0.83, 'n_estimators': 45}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.score(X_test, y_test))\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.137600948984488\n",
      "7.228866486788187\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [100, 120], 'learning_rate': [0.15, 0.2, 0.25, 0.3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "params = {\n",
    "    'n_estimators': [100, 120],\n",
    "    'learning_rate': [0.15, 0.2, 0.25, 0.3]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, param_grid=params)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18477183788145668\n",
      "0.20791587163961978\n",
      "{'learning_rate': 0.15, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.score(X_test, y_test))\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.796795583530697\n",
      "6.1460958963252095\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=20, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components = 20)\n",
    "pca.fit(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance:  [0.14938207 0.11103121 0.09854372 0.05612772 0.05153472 0.04414462\n",
      " 0.04293378 0.04189589 0.0406451  0.04035708 0.03985134 0.03902206\n",
      " 0.03611149 0.03398105 0.03129266 0.02826511 0.02732568 0.02643202\n",
      " 0.01888563 0.01484014]\n"
     ]
    }
   ],
   "source": [
    "var_exp = pca.explained_variance_ratio_\n",
    "print('Explained Variance: ', var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Explained Variance:  [0.14938207 0.26041329 0.35895701 0.41508473 0.46661945 0.51076407\n",
      " 0.55369785 0.59559373 0.63623883 0.67659591 0.71644725 0.7554693\n",
      " 0.7915808  0.82556185 0.85685451 0.88511962 0.91244531 0.93887732\n",
      " 0.95776296 0.97260309]\n"
     ]
    }
   ],
   "source": [
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print('Cumulative Explained Variance: ', cum_var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train = pca.transform(X_train_scaled)\n",
    "Z_test = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21128221321554774\n",
      "0.19741419153531137\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "model.fit(Z_train, y_train)\n",
    "print(model.score(Z_train, y_train))\n",
    "print(model.score(Z_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.878558001837594"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.1867050945234805"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(X_train.shape[1], activation = 'relu', input_dim = X_train.shape[1]))\n",
    "model.add(Dense(5, activation = 'relu'))\n",
    "model.add(Dense(1, activation=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4930 samples, validate on 1644 samples\n",
      "Epoch 1/10\n",
      "4930/4930 [==============================] - 2s 478us/step - loss: 50.9416 - val_loss: 39.1470\n",
      "Epoch 2/10\n",
      "4930/4930 [==============================] - 2s 487us/step - loss: 41.9767 - val_loss: 39.2926\n",
      "Epoch 3/10\n",
      "4930/4930 [==============================] - 2s 419us/step - loss: 41.2961 - val_loss: 38.6021\n",
      "Epoch 4/10\n",
      "4930/4930 [==============================] - 2s 420us/step - loss: 40.9769 - val_loss: 38.2831\n",
      "Epoch 5/10\n",
      "4930/4930 [==============================] - 2s 422us/step - loss: 40.6382 - val_loss: 38.2960\n",
      "Epoch 6/10\n",
      "4930/4930 [==============================] - 2s 420us/step - loss: 40.3667 - val_loss: 38.8243\n",
      "Epoch 7/10\n",
      "4930/4930 [==============================] - 2s 414us/step - loss: 40.0506 - val_loss: 38.3215\n",
      "Epoch 8/10\n",
      "4930/4930 [==============================] - 2s 422us/step - loss: 40.1191 - val_loss: 39.9574\n",
      "Epoch 9/10\n",
      "4930/4930 [==============================] - 2s 413us/step - loss: 39.8582 - val_loss: 38.8285\n",
      "Epoch 10/10\n",
      "4930/4930 [==============================] - 2s 412us/step - loss: 39.6961 - val_loss: 38.7752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1046a1e80>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, \n",
    "          y_train, \n",
    "          epochs = 10, \n",
    "          batch_size = 2, \n",
    "          validation_data = (X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.809406380911524\n",
      "6.226977376495484\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_test, predictions))\n",
    "print(np.sqrt(mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
