{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Assembly DSI - Denver 2018\n",
    "## Capstone Project - DFS Model\n",
    "This is my capstone project at General Assembly's fifth [Data Science Immersive](https://generalassemb.ly/education/data-science-immersive) cohort in 2018. I am developing a model to assist in optimizing NFL lineups on the daily fantasy sports platforms [Draft Kings](https://www.draftkings.com/) and [Fan Duel](https://www.fanduel.com/).\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Can we build a model to predict a football player’s fantasy football performance to estimate their value and implement the model in conjunction with a daily fantasy strategy to be profitable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charleydixon/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/Users/charleydixon/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('../data/modeling_tes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.groupby(['Name', 'Year', 'Week', 'Month', 'Team', 'Oppt']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>h/a</th>\n",
       "      <th>Favored</th>\n",
       "      <th>Spread</th>\n",
       "      <th>O/U</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Receptions</th>\n",
       "      <th>Targets</th>\n",
       "      <th>Rec_TDs</th>\n",
       "      <th>...</th>\n",
       "      <th>Weather_DOME</th>\n",
       "      <th>Weather_Fog</th>\n",
       "      <th>Weather_Rain</th>\n",
       "      <th>Weather_Rain | Fog</th>\n",
       "      <th>Weather_Snow</th>\n",
       "      <th>Weather_Snow | Fog</th>\n",
       "      <th>Weather_Snow | Freezing Rain</th>\n",
       "      <th>Weather_Sunny</th>\n",
       "      <th>FD salary</th>\n",
       "      <th>FD points</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Week</th>\n",
       "      <th>Month</th>\n",
       "      <th>Team</th>\n",
       "      <th>Oppt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Adams, Jerell</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2016</th>\n",
       "      <th>5</th>\n",
       "      <th>October</th>\n",
       "      <th>NYG</th>\n",
       "      <th>GB</th>\n",
       "      <td>23.283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>October</th>\n",
       "      <th>NYG</th>\n",
       "      <th>LAR</th>\n",
       "      <td>23.297</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>44.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>November</th>\n",
       "      <th>NYG</th>\n",
       "      <th>PHI</th>\n",
       "      <td>23.311</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>November</th>\n",
       "      <th>NYG</th>\n",
       "      <th>CHI</th>\n",
       "      <td>23.325</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>41.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>December</th>\n",
       "      <th>NYG</th>\n",
       "      <th>PIT</th>\n",
       "      <td>23.339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>49.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Age  h/a  Favored  Spread  \\\n",
       "Name          Year Week Month    Team Oppt                                 \n",
       "Adams, Jerell 2016 5    October  NYG  GB    23.283    0        0    -7.0   \n",
       "                   7    October  NYG  LAR   23.297    0        1    -2.5   \n",
       "                   9    November NYG  PHI   23.311    1        1    -3.0   \n",
       "                   11   November NYG  CHI   23.325    1        1    -7.0   \n",
       "                   13   December NYG  PIT   23.339    0        0    -6.5   \n",
       "\n",
       "                                             O/U  Temperature  Wind  \\\n",
       "Name          Year Week Month    Team Oppt                            \n",
       "Adams, Jerell 2016 5    October  NYG  GB    49.0         48.0   2.0   \n",
       "                   7    October  NYG  LAR   44.5         54.0  10.0   \n",
       "                   9    November NYG  PHI   42.5         57.0   8.0   \n",
       "                   11   November NYG  CHI   41.5         40.0  12.0   \n",
       "                   13   December NYG  PIT   49.5         40.0   2.0   \n",
       "\n",
       "                                            Receptions   Targets  Rec_TDs  \\\n",
       "Name          Year Week Month    Team Oppt                                  \n",
       "Adams, Jerell 2016 5    October  NYG  GB      2.000000  2.333333      0.0   \n",
       "                   7    October  NYG  LAR     2.000000  2.333333      0.0   \n",
       "                   9    November NYG  PHI     1.333333  1.333333      0.0   \n",
       "                   11   November NYG  CHI     3.000000  3.000000      1.0   \n",
       "                   13   December NYG  PIT     1.500000  2.000000      0.5   \n",
       "\n",
       "                                              ...      Weather_DOME  \\\n",
       "Name          Year Week Month    Team Oppt    ...                     \n",
       "Adams, Jerell 2016 5    October  NYG  GB      ...                 0   \n",
       "                   7    October  NYG  LAR     ...                 0   \n",
       "                   9    November NYG  PHI     ...                 0   \n",
       "                   11   November NYG  CHI     ...                 0   \n",
       "                   13   December NYG  PIT     ...                 0   \n",
       "\n",
       "                                            Weather_Fog  Weather_Rain  \\\n",
       "Name          Year Week Month    Team Oppt                              \n",
       "Adams, Jerell 2016 5    October  NYG  GB              0             0   \n",
       "                   7    October  NYG  LAR             0             0   \n",
       "                   9    November NYG  PHI             0             0   \n",
       "                   11   November NYG  CHI             0             0   \n",
       "                   13   December NYG  PIT             0             0   \n",
       "\n",
       "                                            Weather_Rain | Fog  Weather_Snow  \\\n",
       "Name          Year Week Month    Team Oppt                                     \n",
       "Adams, Jerell 2016 5    October  NYG  GB                     0             0   \n",
       "                   7    October  NYG  LAR                    0             0   \n",
       "                   9    November NYG  PHI                    0             0   \n",
       "                   11   November NYG  CHI                    0             0   \n",
       "                   13   December NYG  PIT                    0             0   \n",
       "\n",
       "                                            Weather_Snow | Fog  \\\n",
       "Name          Year Week Month    Team Oppt                       \n",
       "Adams, Jerell 2016 5    October  NYG  GB                     0   \n",
       "                   7    October  NYG  LAR                    0   \n",
       "                   9    November NYG  PHI                    0   \n",
       "                   11   November NYG  CHI                    0   \n",
       "                   13   December NYG  PIT                    0   \n",
       "\n",
       "                                            Weather_Snow | Freezing Rain  \\\n",
       "Name          Year Week Month    Team Oppt                                 \n",
       "Adams, Jerell 2016 5    October  NYG  GB                               0   \n",
       "                   7    October  NYG  LAR                              0   \n",
       "                   9    November NYG  PHI                              0   \n",
       "                   11   November NYG  CHI                              0   \n",
       "                   13   December NYG  PIT                              0   \n",
       "\n",
       "                                            Weather_Sunny  FD salary  \\\n",
       "Name          Year Week Month    Team Oppt                             \n",
       "Adams, Jerell 2016 5    October  NYG  GB                1     4500.0   \n",
       "                   7    October  NYG  LAR               1     4500.0   \n",
       "                   9    November NYG  PHI               1     4500.0   \n",
       "                   11   November NYG  CHI               1     4500.0   \n",
       "                   13   December NYG  PIT               1     4500.0   \n",
       "\n",
       "                                            FD points  \n",
       "Name          Year Week Month    Team Oppt             \n",
       "Adams, Jerell 2016 5    October  NYG  GB          3.7  \n",
       "                   7    October  NYG  LAR         1.0  \n",
       "                   9    November NYG  PHI         3.9  \n",
       "                   11   November NYG  CHI         0.0  \n",
       "                   13   December NYG  PIT         1.5  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "- Linear Regression\n",
    "- Random Forest\n",
    "- Support Vector Regression\n",
    "- Boosting\n",
    "- PCA\n",
    "- Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============EVAULATION=============\n",
      "\n",
      "R2 Training: 0.23579381106157848\n",
      "R2 Testing: 0.2203812753547637\n",
      "RMSE: 4.978861720650418\n",
      "MAE: 3.8264615739438472 \n",
      "\n",
      "=============COEFFICIENTS=============\n",
      "\n",
      "Intercept: -6.709895460711842\n",
      "Age 0.06449120266836442\n",
      "h/a 0.18251896949854607\n",
      "Favored 0.3725098495621829\n",
      "Spread -0.00689981020118736\n",
      "O/U 0.06547691277398701\n",
      "Temperature 0.004869535931084206\n",
      "Wind -0.04378065288412842\n",
      "Receptions 0.2257883517506472\n",
      "Targets 0.4537566849602897\n",
      "Rec_TDs -0.7294945082394024\n",
      "Rec_Yds 0.02759674772844765\n",
      "Opp_Rank -0.004919125357804126\n",
      "Opp_Avg_Rec_Allowed -0.11804752197878918\n",
      "Opp_Avg_Targets_Allowed 0.077734528118091\n",
      "Opp_Avg_TDs_Allowed 0.14443663074968655\n",
      "Opp_Avg_Yds_Allowed 0.011785464897104405\n",
      "Weather_DOME -1.58090990453568\n",
      "Weather_Fog 0.5892585812058256\n",
      "Weather_Rain -0.5544892930624472\n",
      "Weather_Rain | Fog -2.5166126687691786\n",
      "Weather_Snow -1.1615399021768338\n",
      "Weather_Snow | Fog 4.242079502139789\n",
      "Weather_Snow | Freezing Rain 2.0677970368420118\n",
      "Weather_Sunny -1.0855833516434783\n",
      "FD salary 0.0009839241884064278\n"
     ]
    }
   ],
   "source": [
    "columns = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "def linreg(df, features, target = 'FD points'):\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "    # first attempt - all features\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print('=============EVAULATION=============\\n')\n",
    "    print('R2 Training:', model.score(X_train, y_train))\n",
    "    print('R2 Testing:', model.score(X_test, y_test))\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    print('RMSE:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "    print('MAE:', mean_absolute_error(y_test, predictions), '\\n')\n",
    "    print('=============COEFFICIENTS=============\\n')\n",
    "    print('Intercept:', model.intercept_)\n",
    "    for key, index in dict(zip(X.columns, model.coef_)).items():\n",
    "        print(key, index)\n",
    "    return model\n",
    "\n",
    "lr_all_features = linreg(data, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Coefficients that seem logical:\n",
    "- Increasing Prediction for:\n",
    "    - Home/Away\n",
    "    - Favored\n",
    "    - O/U\n",
    "    - Attempts\n",
    "    - Completions\n",
    "    - TDs\n",
    "    - Y/A\n",
    "    \n",
    "- Decreasing Prediction for:\n",
    "    - Age\n",
    "        - Sort of...\n",
    "    - Wind\n",
    "    - Rain\n",
    "    - Rain & Fog\n",
    "    - Snow\n",
    "    - Snow & Fog\n",
    "    - Interceptions\n",
    "    - Opponent Rank\n",
    "        - The rank columns is actually backwards so defenses get better as ranking improves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Coefficients that make no sense to me:\n",
    "- Increasing Prediction for:\n",
    "    - Fog\n",
    "    - Snow & Freezing Rain\n",
    "    - Opponent Interceptions\n",
    "- Decreasing Prediction for:\n",
    "    - Being in a Dome (Controlled conditions seem like a player should perform better)\n",
    "    - Sunny weather\n",
    "    - Yards\n",
    "    - Opponent Attempts Allowed\n",
    "    - Opponent Completions Allowed\n",
    "    - Opponent TDs Allowed\n",
    "- Almost no effect from:\n",
    "    - Rating\n",
    "    - FD Salary\n",
    "        - Considering salary kind of derives FanDuel's predictions I feel like this would have an impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The most interesting thing to note here is that FD Salary has seemingly no effect on a player's point production**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_cols = ['Weather_Fog', 'Weather_Snow | Freezing Rain', 'Opp_Avg_Ints', 'Weather_DOME', \n",
    "#                'Weather_Sunny', 'Yards', 'Opp_Avg_Att_Allowed', 'Opp_Avg_Comp_Allowed', \n",
    "#                'Opp_Avg_TDs_Allowed', 'Rating', 'FD salary', 'FD points']\n",
    "\n",
    "# features = [col for col in data.columns if col not in remove_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_partial_features = linreg(data, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1219148993050894"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "cross_val_score(model, X_train, y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14379246771871357"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.014495412844037"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.217692203130183"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [15, 20, 25], 'n_estimators': [90, 95, 100], 'min_samples_leaf': [11, 13, 15], 'max_features': [8, 10, 12]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "\n",
    "params = {\n",
    "    'max_depth': [15, 20, 25],\n",
    "    'n_estimators': [90, 95, 100],\n",
    "    'min_samples_leaf': [11, 13, 15],\n",
    "    'max_features': [8, 10, 12]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, param_grid = params)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23968342429199102\n",
      "0.2397514647957475\n",
      "{'max_depth': 25, 'max_features': 8, 'min_samples_leaf': 11, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.score(X_test, y_test))\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.761517392309697\n",
      "4.916620979967099\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': 0.05614846183189576,\n",
       " 'h/a': 0.006075499680317972,\n",
       " 'Favored': 0.008419205567882103,\n",
       " 'Spread': 0.030077061916882177,\n",
       " 'O/U': 0.03857191054353415,\n",
       " 'Temperature': 0.030050943010066722,\n",
       " 'Wind': 0.02327311546739492,\n",
       " 'Receptions': 0.14062753842998865,\n",
       " 'Targets': 0.12136770955008425,\n",
       " 'Rec_TDs': 0.01803184599414879,\n",
       " 'Rec_Yds': 0.13450606225835707,\n",
       " 'Opp_Rank': 0.03218574497964323,\n",
       " 'Opp_Avg_Rec_Allowed': 0.02306772899365528,\n",
       " 'Opp_Avg_Targets_Allowed': 0.02995825250344852,\n",
       " 'Opp_Avg_TDs_Allowed': 0.012120859373062058,\n",
       " 'Opp_Avg_Yds_Allowed': 0.034463508135742116,\n",
       " 'Weather_DOME': 0.0025286939998132923,\n",
       " 'Weather_Fog': 0.0,\n",
       " 'Weather_Rain': 0.0001467408292299609,\n",
       " 'Weather_Rain | Fog': 0.0,\n",
       " 'Weather_Snow': 0.0,\n",
       " 'Weather_Snow | Fog': 0.0,\n",
       " 'Weather_Snow | Freezing Rain': 0.0,\n",
       " 'Weather_Sunny': 0.002950064565052698,\n",
       " 'FD salary': 0.25542905236980035}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(X.columns, gs.best_estimator_.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now this is telling me that `FD Salary` is far and away the most important feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11279720131204463"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11463266923230298"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.160065196278003"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'kernel': ['linear'], 'C': [0.1, 0.01]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVR()\n",
    "params = {\n",
    "    'kernel': ['linear'],\n",
    "    'C': [0.1, 0.01]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, param_grid = params)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19105404779867072\n",
      "0.18042208093057188\n",
      "{'C': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.score(X_test, y_test))\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.707355435298749\n",
      "5.104862614977823\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADA Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
       "         n_estimators=50, random_state=None),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [45, 47, 50], 'learning_rate': [0.9, 0.92, 0.95]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdaBoostRegressor()\n",
    "params = {\n",
    "    'n_estimators': [45, 47, 50],\n",
    "    'learning_rate': [.9, .92, .95]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, param_grid=params)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.004661824318639856\n",
      "-0.16595185649995114\n",
      "{'learning_rate': 0.92, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.score(X_test, y_test))\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.290952029631688\n",
      "6.0887654296182285\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [75, 80, 85], 'learning_rate': [0.15, 0.2, 0.25, 0.3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "params = {\n",
    "    'n_estimators': [75, 80, 85],\n",
    "    'learning_rate': [0.15, 0.2, 0.25, 0.3]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, param_grid=params)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18118682217416815\n",
      "0.19752317823437493\n",
      "{'learning_rate': 0.15, 'n_estimators': 80}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.score(X_test, y_test))\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8279745550800435\n",
      "5.051323499084434\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=18, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components = 18)\n",
    "pca.fit(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance:  [0.14579905 0.10928441 0.1008197  0.05487093 0.05050765 0.04440351\n",
      " 0.04290416 0.04152544 0.04087467 0.04062209 0.04038616 0.03937853\n",
      " 0.03631828 0.03534193 0.03112427 0.02818144 0.02778879 0.02650852]\n"
     ]
    }
   ],
   "source": [
    "var_exp = pca.explained_variance_ratio_\n",
    "print('Explained Variance: ', var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Explained Variance:  [0.14579905 0.25508346 0.35590316 0.41077408 0.46128173 0.50568524\n",
      " 0.5485894  0.59011484 0.63098951 0.6716116  0.71199776 0.75137629\n",
      " 0.78769457 0.8230365  0.85416077 0.88234221 0.910131   0.93663952]\n"
     ]
    }
   ],
   "source": [
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print('Cumulative Explained Variance: ', cum_var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train = pca.transform(X_train_scaled)\n",
    "Z_test = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2312486678582144\n",
      "0.20735035787213055\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "model.fit(Z_train, y_train)\n",
    "print(model.score(Z_train, y_train))\n",
    "print(model.score(Z_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.838802770486505"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.02029881760621"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(X_train.shape[1], activation = 'relu', input_dim = X_train.shape[1]))\n",
    "model.add(Dense(5, activation = 'relu'))\n",
    "model.add(Dense(1, activation=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2286 samples, validate on 763 samples\n",
      "Epoch 1/10\n",
      "2286/2286 [==============================] - 2s 663us/step - loss: 37.1167 - val_loss: 25.2937\n",
      "Epoch 2/10\n",
      "2286/2286 [==============================] - 1s 568us/step - loss: 26.6074 - val_loss: 25.1899\n",
      "Epoch 3/10\n",
      "2286/2286 [==============================] - 1s 539us/step - loss: 25.9549 - val_loss: 25.6805\n",
      "Epoch 4/10\n",
      "2286/2286 [==============================] - 1s 535us/step - loss: 25.7385 - val_loss: 24.9348\n",
      "Epoch 5/10\n",
      "2286/2286 [==============================] - 1s 599us/step - loss: 25.3700 - val_loss: 24.7410\n",
      "Epoch 6/10\n",
      "2286/2286 [==============================] - 1s 608us/step - loss: 25.1008 - val_loss: 24.8653\n",
      "Epoch 7/10\n",
      "2286/2286 [==============================] - 1s 603us/step - loss: 24.8074 - val_loss: 25.1134\n",
      "Epoch 8/10\n",
      "2286/2286 [==============================] - 1s 581us/step - loss: 24.6476 - val_loss: 25.2945\n",
      "Epoch 9/10\n",
      "2286/2286 [==============================] - 2s 817us/step - loss: 24.3978 - val_loss: 25.2122\n",
      "Epoch 10/10\n",
      "2286/2286 [==============================] - 2s 897us/step - loss: 24.3456 - val_loss: 25.2558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a28e485c0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, \n",
    "          y_train, \n",
    "          epochs = 10, \n",
    "          batch_size = 2, \n",
    "          validation_data = (X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8108382990835223\n",
      "5.025512438443507\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_test, predictions))\n",
    "print(np.sqrt(mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
