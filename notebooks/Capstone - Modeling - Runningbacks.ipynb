{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Assembly DSI - Denver 2018\n",
    "## Capstone Project - DFS Model\n",
    "This is my capstone project at General Assembly's fifth [Data Science Immersive](https://generalassemb.ly/education/data-science-immersive) cohort in 2018. I am developing a model to assist in optimizing NFL lineups on the daily fantasy sports platforms [Draft Kings](https://www.draftkings.com/) and [Fan Duel](https://www.fanduel.com/).\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Can we build a model to predict a football player’s fantasy football performance to estimate their value and implement the model in conjunction with a daily fantasy strategy to be profitable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charleydixon/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/Users/charleydixon/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('../data/modeling_rbs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.groupby(['Name', 'Year', 'Week', 'Month', 'Team', 'Oppt']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>h/a</th>\n",
       "      <th>Favored</th>\n",
       "      <th>Spread</th>\n",
       "      <th>O/U</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Carries</th>\n",
       "      <th>Rush_Yds</th>\n",
       "      <th>Rush_TDs</th>\n",
       "      <th>...</th>\n",
       "      <th>Weather_DOME</th>\n",
       "      <th>Weather_Fog</th>\n",
       "      <th>Weather_Rain</th>\n",
       "      <th>Weather_Rain | Fog</th>\n",
       "      <th>Weather_Snow</th>\n",
       "      <th>Weather_Snow | Fog</th>\n",
       "      <th>Weather_Snow | Freezing Rain</th>\n",
       "      <th>Weather_Sunny</th>\n",
       "      <th>FD salary</th>\n",
       "      <th>FD points</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Week</th>\n",
       "      <th>Month</th>\n",
       "      <th>Team</th>\n",
       "      <th>Oppt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Abdullah, Ameer</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2015</th>\n",
       "      <th>2</th>\n",
       "      <th>September</th>\n",
       "      <th>DET</th>\n",
       "      <th>MIN</th>\n",
       "      <td>22.099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>44.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6400.0</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>September</th>\n",
       "      <th>DET</th>\n",
       "      <th>DEN</th>\n",
       "      <td>22.106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>October</th>\n",
       "      <th>DET</th>\n",
       "      <th>SEA</th>\n",
       "      <td>22.114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6100.0</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>October</th>\n",
       "      <th>DET</th>\n",
       "      <th>ARI</th>\n",
       "      <td>22.120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>46.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6100.0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>October</th>\n",
       "      <th>DET</th>\n",
       "      <th>CHI</th>\n",
       "      <td>22.127</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>45.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5900.0</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Age  h/a  Favored  Spread  \\\n",
       "Name            Year Week Month     Team Oppt                                 \n",
       "Abdullah, Ameer 2015 2    September DET  MIN   22.099    0        0    -2.5   \n",
       "                     3    September DET  DEN   22.106    1        0    -3.0   \n",
       "                     4    October   DET  SEA   22.114    0        0   -10.0   \n",
       "                     5    October   DET  ARI   22.120    1        0    -4.5   \n",
       "                     6    October   DET  CHI   22.127    1        1    -3.5   \n",
       "\n",
       "                                                O/U  Temperature  Wind  \\\n",
       "Name            Year Week Month     Team Oppt                            \n",
       "Abdullah, Ameer 2015 2    September DET  MIN   44.0         70.0  12.0   \n",
       "                     3    September DET  DEN   45.0         72.0   0.0   \n",
       "                     4    October   DET  SEA   43.0         61.0   2.0   \n",
       "                     5    October   DET  ARI   46.0         72.0   0.0   \n",
       "                     6    October   DET  CHI   45.5         72.0   0.0   \n",
       "\n",
       "                                                Carries   Rush_Yds  Rush_TDs  \\\n",
       "Name            Year Week Month     Team Oppt                                  \n",
       "Abdullah, Ameer 2015 2    September DET  MIN   8.000000  46.333333  0.333333   \n",
       "                     3    September DET  DEN   7.666667  41.666667  0.333333   \n",
       "                     4    October   DET  SEA   7.333333  23.666667  0.000000   \n",
       "                     5    October   DET  ARI   9.000000  21.666667  0.000000   \n",
       "                     6    October   DET  CHI   9.000000  24.000000  0.000000   \n",
       "\n",
       "                                                 ...      Weather_DOME  \\\n",
       "Name            Year Week Month     Team Oppt    ...                     \n",
       "Abdullah, Ameer 2015 2    September DET  MIN     ...                 0   \n",
       "                     3    September DET  DEN     ...                 1   \n",
       "                     4    October   DET  SEA     ...                 0   \n",
       "                     5    October   DET  ARI     ...                 1   \n",
       "                     6    October   DET  CHI     ...                 1   \n",
       "\n",
       "                                               Weather_Fog  Weather_Rain  \\\n",
       "Name            Year Week Month     Team Oppt                              \n",
       "Abdullah, Ameer 2015 2    September DET  MIN             0             0   \n",
       "                     3    September DET  DEN             0             0   \n",
       "                     4    October   DET  SEA             0             0   \n",
       "                     5    October   DET  ARI             0             0   \n",
       "                     6    October   DET  CHI             0             0   \n",
       "\n",
       "                                               Weather_Rain | Fog  \\\n",
       "Name            Year Week Month     Team Oppt                       \n",
       "Abdullah, Ameer 2015 2    September DET  MIN                    0   \n",
       "                     3    September DET  DEN                    0   \n",
       "                     4    October   DET  SEA                    0   \n",
       "                     5    October   DET  ARI                    0   \n",
       "                     6    October   DET  CHI                    0   \n",
       "\n",
       "                                               Weather_Snow  \\\n",
       "Name            Year Week Month     Team Oppt                 \n",
       "Abdullah, Ameer 2015 2    September DET  MIN              0   \n",
       "                     3    September DET  DEN              0   \n",
       "                     4    October   DET  SEA              0   \n",
       "                     5    October   DET  ARI              0   \n",
       "                     6    October   DET  CHI              0   \n",
       "\n",
       "                                               Weather_Snow | Fog  \\\n",
       "Name            Year Week Month     Team Oppt                       \n",
       "Abdullah, Ameer 2015 2    September DET  MIN                    0   \n",
       "                     3    September DET  DEN                    0   \n",
       "                     4    October   DET  SEA                    0   \n",
       "                     5    October   DET  ARI                    0   \n",
       "                     6    October   DET  CHI                    0   \n",
       "\n",
       "                                               Weather_Snow | Freezing Rain  \\\n",
       "Name            Year Week Month     Team Oppt                                 \n",
       "Abdullah, Ameer 2015 2    September DET  MIN                              0   \n",
       "                     3    September DET  DEN                              0   \n",
       "                     4    October   DET  SEA                              0   \n",
       "                     5    October   DET  ARI                              0   \n",
       "                     6    October   DET  CHI                              0   \n",
       "\n",
       "                                               Weather_Sunny  FD salary  \\\n",
       "Name            Year Week Month     Team Oppt                             \n",
       "Abdullah, Ameer 2015 2    September DET  MIN               1     6400.0   \n",
       "                     3    September DET  DEN               0     6000.0   \n",
       "                     4    October   DET  SEA               1     6100.0   \n",
       "                     5    October   DET  ARI               0     6100.0   \n",
       "                     6    October   DET  CHI               0     5900.0   \n",
       "\n",
       "                                               FD points  \n",
       "Name            Year Week Month     Team Oppt             \n",
       "Abdullah, Ameer 2015 2    September DET  MIN         2.3  \n",
       "                     3    September DET  DEN        11.2  \n",
       "                     4    October   DET  SEA         5.4  \n",
       "                     5    October   DET  ARI         1.1  \n",
       "                     6    October   DET  CHI         8.4  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "- Linear Regression\n",
    "- Random Forest\n",
    "- Support Vector Regression\n",
    "- Boosting\n",
    "- PCA\n",
    "- Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============EVAULATION=============\n",
      "\n",
      "R2 Training: 0.29202997295009725\n",
      "R2 Testing: 0.31895794910927167\n",
      "RMSE: 6.273472890532594\n",
      "MAE: 4.817716067101606 \n",
      "\n",
      "=============COEFFICIENTS=============\n",
      "\n",
      "Intercept: -7.9660028953115045\n",
      "Age 0.012090830463540385\n",
      "h/a 0.7056492165069178\n",
      "Favored 0.49918014941457517\n",
      "Spread 0.004801744493945273\n",
      "O/U 0.0787057374499108\n",
      "Temperature -0.029221087281389172\n",
      "Wind -0.06247126717026167\n",
      "Carries 0.14147398113490475\n",
      "Rush_Yds 0.024128986258513948\n",
      "Rush_TDs 0.22323631808922761\n",
      "Receptions -0.056855022932739384\n",
      "Targets 0.559679892919739\n",
      "Rec_Yds 0.011068438057728183\n",
      "Rec_TDs -0.3002818069614838\n",
      "Opp_Avg_Carries 0.09502522706385733\n",
      "Opp_Rank 0.05295639825473429\n",
      "Opp_Avg_TDs_Allowed 0.2892627781673079\n",
      "Opp_Avg_Yds_Allowed -0.004368493006366178\n",
      "Weather_DOME -0.6750207928236073\n",
      "Weather_Fog -2.4719962221717267\n",
      "Weather_Rain -0.15603564562047867\n",
      "Weather_Rain | Fog 1.1977752815290368\n",
      "Weather_Snow 1.0690802909972468\n",
      "Weather_Snow | Fog 1.6947501973894517\n",
      "Weather_Snow | Freezing Rain 0.0\n",
      "Weather_Sunny -0.6585531092998711\n",
      "FD salary 0.001427960394905597\n"
     ]
    }
   ],
   "source": [
    "columns = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "def linreg(df, features, target = 'FD points'):\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "    # first attempt - all features\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print('=============EVAULATION=============\\n')\n",
    "    print('R2 Training:', model.score(X_train, y_train))\n",
    "    print('R2 Testing:', model.score(X_test, y_test))\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    print('RMSE:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "    print('MAE:', mean_absolute_error(y_test, predictions), '\\n')\n",
    "    print('=============COEFFICIENTS=============\\n')\n",
    "    print('Intercept:', model.intercept_)\n",
    "    for key, index in dict(zip(X.columns, model.coef_)).items():\n",
    "        print(key, index)\n",
    "    return model\n",
    "\n",
    "lr_all_features = linreg(data, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Coefficients that seem logical:\n",
    "- Increasing Prediction for:\n",
    "    - Home/Away\n",
    "    - Favored\n",
    "    - O/U\n",
    "    - Attempts\n",
    "    - Completions\n",
    "    - TDs\n",
    "    - Y/A\n",
    "    \n",
    "- Decreasing Prediction for:\n",
    "    - Age\n",
    "        - Sort of...\n",
    "    - Wind\n",
    "    - Rain\n",
    "    - Rain & Fog\n",
    "    - Snow\n",
    "    - Snow & Fog\n",
    "    - Interceptions\n",
    "    - Opponent Rank\n",
    "        - The rank columns is actually backwards so defenses get better as ranking improves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Coefficients that make no sense to me:\n",
    "- Increasing Prediction for:\n",
    "    - Fog\n",
    "    - Snow & Freezing Rain\n",
    "    - Opponent Interceptions\n",
    "- Decreasing Prediction for:\n",
    "    - Being in a Dome (Controlled conditions seem like a player should perform better)\n",
    "    - Sunny weather\n",
    "    - Yards\n",
    "    - Opponent Attempts Allowed\n",
    "    - Opponent Completions Allowed\n",
    "    - Opponent TDs Allowed\n",
    "- Almost no effect from:\n",
    "    - Rating\n",
    "    - FD Salary\n",
    "        - Considering salary kind of derives FanDuel's predictions I feel like this would have an impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The most interesting thing to note here is that FD Salary has seemingly no effect on a player's point production**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_cols = ['Weather_Fog', 'Weather_Snow | Freezing Rain', 'Opp_Avg_Ints', 'Weather_DOME', \n",
    "#                'Weather_Sunny', 'Yards', 'Opp_Avg_Att_Allowed', 'Opp_Avg_Comp_Allowed', \n",
    "#                'Opp_Avg_TDs_Allowed', 'Rating', 'FD salary', 'FD points']\n",
    "\n",
    "# features = [col for col in data.columns if col not in remove_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_partial_features = linreg(data, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17327925181727474"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "cross_val_score(model, X_train, y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23823573099659"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.06633909287257"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.63485384481954"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [10, 20, 30], 'n_estimators': [70, 75, 80], 'min_samples_leaf': [13, 14], 'max_features': [10, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "\n",
    "params = {\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'n_estimators': [70, 75, 80],\n",
    "    'min_samples_leaf': [13, 14],\n",
    "    'max_features': [10, 20]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, param_grid = params)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2818799772319774\n",
      "0.32867750331679496\n",
      "{'max_depth': 10, 'max_features': 10, 'min_samples_leaf': 14, 'n_estimators': 75}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.score(X_test, y_test))\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.7630812920862\n",
      "6.228545796810142\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': 0.0375676968294432,\n",
       " 'h/a': 0.007698234704843623,\n",
       " 'Favored': 0.0054764950424066264,\n",
       " 'Spread': 0.016573108494078843,\n",
       " 'O/U': 0.02289060370403699,\n",
       " 'Temperature': 0.026598648014164377,\n",
       " 'Wind': 0.013881196405668372,\n",
       " 'Carries': 0.15279007919864043,\n",
       " 'Rush_Yds': 0.11750768662648566,\n",
       " 'Rush_TDs': 0.021144465958137508,\n",
       " 'Receptions': 0.054988165051562315,\n",
       " 'Targets': 0.056143301389956914,\n",
       " 'Rec_Yds': 0.0432257192700972,\n",
       " 'Rec_TDs': 0.002185939767923902,\n",
       " 'Opp_Avg_Carries': 0.025285124432440527,\n",
       " 'Opp_Rank': 0.030298818834626182,\n",
       " 'Opp_Avg_TDs_Allowed': 0.010085836448933388,\n",
       " 'Opp_Avg_Yds_Allowed': 0.032377137971133264,\n",
       " 'Weather_DOME': 0.0014678565553502287,\n",
       " 'Weather_Fog': 0.0,\n",
       " 'Weather_Rain': 0.0,\n",
       " 'Weather_Rain | Fog': 0.0,\n",
       " 'Weather_Snow': 0.0,\n",
       " 'Weather_Snow | Fog': 0.0,\n",
       " 'Weather_Snow | Freezing Rain': 0.0,\n",
       " 'Weather_Sunny': 0.0035711220299021154,\n",
       " 'FD salary': 0.3182427632701683}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(X.columns, gs.best_estimator_.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now this is telling me that `FD Salary` is far and away the most important feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11852806948272077"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.053384621940437915"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.880975597911216"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'kernel': ['linear'], 'C': [0.1, 0.01]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVR()\n",
    "params = {\n",
    "    'kernel': ['linear'],\n",
    "    'C': [0.1, 0.01]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, param_grid = params)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2570700423863125\n",
      "0.31175043172921624\n",
      "{'C': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.score(X_test, y_test))\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.721089344752972\n",
      "6.306581831620253\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADA Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
       "         n_estimators=50, random_state=None),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [45, 47, 50], 'learning_rate': [0.8, 0.83, 0.85, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdaBoostRegressor()\n",
    "params = {\n",
    "    'n_estimators': [45, 47, 50],\n",
    "    'learning_rate': [.8, .83, .85, .9]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, param_grid=params)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09703077506486643\n",
      "0.07717861014595317\n",
      "{'learning_rate': 0.85, 'n_estimators': 47}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.score(X_test, y_test))\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.203322501963749\n",
      "7.302639933556975\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [75, 80, 85], 'learning_rate': [0.15, 0.2, 0.25, 0.3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "params = {\n",
    "    'n_estimators': [75, 80, 85],\n",
    "    'learning_rate': [0.15, 0.2, 0.25, 0.3]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, param_grid=params)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2461230603205772\n",
      "0.32104313889223357\n",
      "{'learning_rate': 0.15, 'n_estimators': 75}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.score(X_test, y_test))\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.785058979735102\n",
      "6.263861582434477\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=20, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components = 20)\n",
    "pca.fit(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance:  [0.14314189 0.0961016  0.09242599 0.07789782 0.05272022 0.0512491\n",
      " 0.04190068 0.04081237 0.0400064  0.03905669 0.03850776 0.03751357\n",
      " 0.03603068 0.0315258  0.03060055 0.02727189 0.02590727 0.02492588\n",
      " 0.02146407 0.01808583]\n"
     ]
    }
   ],
   "source": [
    "var_exp = pca.explained_variance_ratio_\n",
    "print('Explained Variance: ', var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Explained Variance:  [0.14314189 0.23924349 0.33166948 0.4095673  0.46228752 0.51353663\n",
      " 0.55543731 0.59624968 0.63625608 0.67531276 0.71382053 0.7513341\n",
      " 0.78736478 0.81889058 0.84949113 0.87676302 0.90267028 0.92759616\n",
      " 0.94906023 0.96714606]\n"
     ]
    }
   ],
   "source": [
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print('Cumulative Explained Variance: ', cum_var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train = pca.transform(X_train_scaled)\n",
    "Z_test = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28480683136238427\n",
      "0.31458480714383197\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "model.fit(Z_train, y_train)\n",
    "print(model.score(Z_train, y_train))\n",
    "print(model.score(Z_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.815208667886761"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.293582432191537"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(29, activation = 'relu', input_dim = X_train.shape[1]))\n",
    "model.add(Dense(5, activation = 'relu'))\n",
    "model.add(Dense(1, activation=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2777 samples, validate on 926 samples\n",
      "Epoch 1/10\n",
      "2777/2777 [==============================] - 1s 538us/step - loss: 57.6637 - val_loss: 41.1680\n",
      "Epoch 2/10\n",
      "2777/2777 [==============================] - 1s 459us/step - loss: 44.0415 - val_loss: 40.5211\n",
      "Epoch 3/10\n",
      "2777/2777 [==============================] - 1s 484us/step - loss: 42.6784 - val_loss: 40.2471\n",
      "Epoch 4/10\n",
      "2777/2777 [==============================] - 1s 447us/step - loss: 41.9212 - val_loss: 40.5788\n",
      "Epoch 5/10\n",
      "2777/2777 [==============================] - 1s 440us/step - loss: 41.4828 - val_loss: 40.0503\n",
      "Epoch 6/10\n",
      "2777/2777 [==============================] - 1s 510us/step - loss: 40.8900 - val_loss: 40.0830\n",
      "Epoch 7/10\n",
      "2777/2777 [==============================] - 1s 532us/step - loss: 40.4700 - val_loss: 40.5181\n",
      "Epoch 8/10\n",
      "2777/2777 [==============================] - 2s 559us/step - loss: 39.6147 - val_loss: 41.6096\n",
      "Epoch 9/10\n",
      "2777/2777 [==============================] - 1s 530us/step - loss: 39.5736 - val_loss: 40.5488\n",
      "Epoch 10/10\n",
      "2777/2777 [==============================] - 1s 491us/step - loss: 38.9758 - val_loss: 40.4729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a24bc6438>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, \n",
    "          y_train, \n",
    "          epochs = 10, \n",
    "          batch_size = 2, \n",
    "          validation_data = (X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8013910098415735\n",
      "6.361829399117297\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_test, predictions))\n",
    "print(np.sqrt(mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
